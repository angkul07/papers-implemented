{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imagenet = load_dataset(\n",
    "    'Maysee/tiny-imagenet',\n",
    "    split='valid',\n",
    "    ignore_verifications=True  # set to True if seeing splits Error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b867d874d9644db58269971440dadaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 227, 227])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(227),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "inputs = []\n",
    "\n",
    "for image in tqdm(imagenet[:50]['image']):\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    input_tensor = preprocess(image)\n",
    "    inputs.append(input_tensor)\n",
    "\n",
    "inputs = torch.stack(inputs)\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels=96, kernel_size=11, stride=4)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pooling1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.norm1 = nn.LocalResponseNorm(size=5)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pooling2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.norm2 = nn.LocalResponseNorm(size=5)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.pooling3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.FC1 = nn.Linear(in_features=9216, out_features=4096)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.FC2 = nn.Linear(in_features=4096, out_features=4096)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.FC3 = nn.Linear(in_features=4096, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.norm1(self.pooling1(self.relu1(self.conv1(x))))\n",
    "        out = self.norm2(self.pooling2(self.relu2(self.conv2(out))))\n",
    "        out = self.relu3(self.conv3(out))\n",
    "        out = self.relu4(self.conv4(out))\n",
    "        out = self.pooling3(self.relu5(self.conv5(out)))\n",
    "        out = self.flatten(out)\n",
    "\n",
    "        result = self.drop1(self.relu6(self.FC1(out)))\n",
    "        result = self.drop2(self.relu7(self.FC2(result)))\n",
    "        result = self.FC3(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to device if available\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else (\n",
    "        'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "  (relu1): ReLU()\n",
       "  (pooling1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (norm1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
       "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (relu2): ReLU()\n",
       "  (pooling2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (norm2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
       "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3): ReLU()\n",
       "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4): ReLU()\n",
       "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu5): ReLU()\n",
       "  (pooling3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (FC1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (relu6): ReLU()\n",
       "  (drop1): Dropout(p=0.5, inplace=False)\n",
       "  (FC2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (relu7): ReLU()\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (FC3): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlexNet(3, 1000)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0034,  0.0107,  0.0072,  ..., -0.0091,  0.0029, -0.0018],\n",
       "        [-0.0036,  0.0108,  0.0059,  ..., -0.0087,  0.0031, -0.0003],\n",
       "        [-0.0038,  0.0103,  0.0062,  ..., -0.0086,  0.0026, -0.0017],\n",
       "        ...,\n",
       "        [-0.0033,  0.0107,  0.0054,  ..., -0.0092,  0.0035, -0.0010],\n",
       "        [-0.0031,  0.0104,  0.0066,  ..., -0.0090,  0.0017, -0.0019],\n",
       "        [-0.0032,  0.0097,  0.0060,  ..., -0.0081,  0.0034, -0.0013]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.to(device)\n",
    "model.to(device)\n",
    "\n",
    "# run the model\n",
    "with torch.no_grad():\n",
    "    output = model(inputs).detach()\n",
    "print(output.shape)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 401, 536, 536, 536, 180,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536,\n",
       "       536, 536, 536, 536, 536, 536, 536, 536, 536, 536, 536])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "preds = torch.argmax(output, dim=1).cpu().numpy()\n",
    "print(preds.shape)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "res = requests.get(\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "dock\n"
     ]
    }
   ],
   "source": [
    "pred_labels = res.text.split('\\n')\n",
    "print(f\"{len(pred_labels)}\\n{pred_labels[536]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds == 1) / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "  (relu1): ReLU()\n",
       "  (pooling1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (norm1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
       "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (relu2): ReLU()\n",
       "  (pooling2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (norm2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
       "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3): ReLU()\n",
       "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4): ReLU()\n",
       "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu5): ReLU()\n",
       "  (pooling3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (FC1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (relu6): ReLU()\n",
       "  (drop1): Dropout(p=0.5, inplace=False)\n",
       "  (FC2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (relu7): ReLU()\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (FC3): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
