{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementing the word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file\n",
    "txt = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = \"\"\"\n",
    "घृणा से घृणा उत्पन्न होती है। प्रेम से प्रेम।  ज्ञान भी बड़े भाई को चाहता था। कभी-कभी उसका पक्ष ले कर अपनी माँ से वाद-विवाद कर कहता भैया की अचकन फट गयी है आप नयी अचकन क्यों नहीं बनवा देतीं माँ उत्तर देती-उसके लिए वही अचकन अच्छी है। अभी क्या कभी तो वह नंगा फिरेगा। ज्ञानप्रकाश बहुत चाहता था कि अपने जेब-खर्च से बचा कर कुछ अपने भाई को दे पर सत्यप्रकाश कभी इसे स्वीकार न करता था। वास्तव में जितनी देर वह छोटे भाई के साथ रहता उतनी देर उसे एक शांतिमय आनन्द का अनुभव होता। थोड़ी देर के लिए वह सद्भावों के साम्राज्य में विचरने लगता। उसके मुख से कोई भद्दी और अप्रिय बात न निकलती। एक क्षण के लिए उसकी सोयी हुई आत्मा जाग उठती।\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt2 = txt.strip()\n",
    "# print(txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the special chars\n",
    "# txt = re.sub('[^A-Za-z0-9]+', ' ', txt)\n",
    "\n",
    "# txt1 = re.sub(r'(?:^| )\\w(?:$|। )', ' ', txt).strip()\n",
    "txt1 = re.sub(r'(।)', ' ', txt1).strip()\n",
    "\n",
    "text = txt1.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = re.sub('[^A-Za-z0-9]+', ' ', txt)\n",
    "text1 = txt.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "घृणा से घृणा उत्पन्न होती है  प्रेम से प्रेम   ज्ञान भी बड़े भाई को चाहता था  कभी-कभी उसका पक्ष ले कर अपनी माँ से वाद-विवाद कर कहता भैया की अचकन फट गयी है आप नयी अचकन क्यों नहीं बनवा देतीं माँ उत्तर देती-उसके लिए वही अचकन अच्छी है  अभी क्या कभी तो वह नंगा फिरेगा  ज्ञानप्रकाश बहुत चाहता था कि अपने जेब-खर्च से बचा कर कुछ अपने भाई को दे पर सत्यप्रकाश कभी इसे स्वीकार न करता था  वास्तव में जितनी देर वह छोटे भाई के साथ रहता उतनी देर उसे एक शांतिमय आनन्द का अनुभव होता  थोड़ी देर के लिए वह सद्भावों के साम्राज्य में विचरने लगता  उसके मुख से कोई भद्दी और अप्रिय बात न निकलती  एक क्षण के लिए उसकी सोयी हुई आत्मा जाग उठती\n",
      "we are about to study the idea of a computational process computational processes are abstract beings that inhabit computers as they evolve processes manipulate other abstract things called data the evolution of a process is directed by a pattern of rules called a program people create programs to direct processes in effect we conjure the spirits of the computer with our spells \n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['घृणा', 'से', 'घृणा', 'उत्पन्न', 'होती', 'है', 'प्रेम', 'से', 'प्रेम', 'ज्ञान', 'भी', 'बड़े', 'भाई', 'को', 'चाहता', 'था', 'कभी-कभी', 'उसका', 'पक्ष', 'ले', 'कर', 'अपनी', 'माँ', 'से', 'वाद-विवाद', 'कर', 'कहता', 'भैया', 'की', 'अचकन', 'फट', 'गयी', 'है', 'आप', 'नयी', 'अचकन', 'क्यों', 'नहीं', 'बनवा', 'देतीं', 'माँ', 'उत्तर', 'देती-उसके', 'लिए', 'वही', 'अचकन', 'अच्छी', 'है', 'अभी', 'क्या', 'कभी', 'तो', 'वह', 'नंगा', 'फिरेगा', 'ज्ञानप्रकाश', 'बहुत', 'चाहता', 'था', 'कि', 'अपने', 'जेब-खर्च', 'से', 'बचा', 'कर', 'कुछ', 'अपने', 'भाई', 'को', 'दे', 'पर', 'सत्यप्रकाश', 'कभी', 'इसे', 'स्वीकार', 'न', 'करता', 'था', 'वास्तव', 'में', 'जितनी', 'देर', 'वह', 'छोटे', 'भाई', 'के', 'साथ', 'रहता', 'उतनी', 'देर', 'उसे', 'एक', 'शांतिमय', 'आनन्द', 'का', 'अनुभव', 'होता', 'थोड़ी', 'देर', 'के', 'लिए', 'वह', 'सद्भावों', 'के', 'साम्राज्य', 'में', 'विचरने', 'लगता', 'उसके', 'मुख', 'से', 'कोई', 'भद्दी', 'और', 'अप्रिय', 'बात', 'न', 'निकलती', 'एक', 'क्षण', 'के', 'लिए', 'उसकी', 'सोयी', 'हुई', 'आत्मा', 'जाग', 'उठती']\n",
      "['we', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'a', 'computational', 'process', 'computational', 'processes', 'are', 'abstract', 'beings', 'that', 'inhabit', 'computers', 'as', 'they', 'evolve', 'processes', 'manipulate', 'other', 'abstract', 'things', 'called', 'data', 'the', 'evolution', 'of', 'a', 'process', 'is', 'directed', 'by', 'a', 'pattern', 'of', 'rules', 'called', 'a', 'program', 'people', 'create', 'programs', 'to', 'direct', 'processes', 'in', 'effect', 'we', 'conjure', 'the', 'spirits', 'of', 'the', 'computer', 'with', 'our', 'spells']\n"
     ]
    }
   ],
   "source": [
    "print(text.split())\n",
    "print(text1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "घृणा से घृणा उत्पन्न होती है। प्रेम से प्रेम।  ज्ञान भी बड़े भाई को चाहता था। कभी-कभी उसका पक्ष ले कर अपनी माँ से वाद-विवाद कर कहता भैया की अचकन फट गयी है आप नयी अचकन क्यों नहीं बनवा देतीं माँ उत्तर देती-उसके लिए वही अचकन अच्छी है। अभी क्या कभी तो वह नंगा फिरेगा। ज्ञानप्रकाश बहुत चाहता था कि अपने जेब-खर्च से बचा कर कुछ अपने भाई को दे पर सत्यप्रकाश कभी इसे स्वीकार करता था। वास्तव में जितनी देर वह छोटे भाई के साथ रहता उतनी देर उसे एक शांतिमय आनन्द का अनुभव होता। थोड़ी देर के लिए वह सद्भावों के साम्राज्य में विचरने लगता। उसके मुख से कोई भद्दी और अप्रिय बात निकलती। एक क्षण के लिए उसकी सोयी हुई आत्मा जाग उठती।\n"
     ]
    }
   ],
   "source": [
    "print(txt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping the unique words\n",
    "words = text.split()\n",
    "vocab = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "# print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 10 #depends on the dataset but since our dataset is small\n",
    "context_size = 2 #how many before and after words to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the token ids\n",
    "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx_to_word = {i: word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data bags\n",
    "# data = [(context), target]\n",
    "\n",
    "# data = []\n",
    "# for i in range(2, len(words)-2):\n",
    "#     context = [words[i-2], words[i-1], words[i+1], words[i+2]]\n",
    "#     target = words[i]\n",
    "#     data.append((context, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context, target = data[0]\n",
    "# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create the continous BOW\n",
    "# class CBOW(nn.Module):\n",
    "#     def __init__(self, vocab_size, embed_dim):\n",
    "#         super(CBOW, self).__init__()\n",
    "\n",
    "#         # 1 x embed_dim\n",
    "#         self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "#         self.linear1 = nn.Linear(embed_dim, 128)\n",
    "#         self.activation = nn.ReLU()\n",
    "\n",
    "#         # 1 x vocab size\n",
    "#         self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         embeds = sum(self.embeddings(inputs)).view(1, -1)\n",
    "#         out = self.linear1(embeds)\n",
    "#         out = self.activation(out)\n",
    "#         out = self.linear2(out)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CBOW(vocab_size=vocab_size, embed_dim=embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# total_loss = []\n",
    "\n",
    "# for epoch in range(80):\n",
    "#     epoch_loss = 0\n",
    "#     for context, target in data:\n",
    "#         context_ids = torch.tensor([word_to_idx[w] for w in context])\n",
    "#         target_id = torch.tensor([word_to_idx[target]])\n",
    "        \n",
    "#         # Forward pass\n",
    "#         preds = model(context_ids)\n",
    "        \n",
    "#         # Calculate loss\n",
    "#         loss = loss_fn(preds, target_id)\n",
    "#         epoch_loss += loss.item()\n",
    "        \n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f'Epoch: {epoch} | Loss: {epoch_loss/len(data)}')\n",
    "\n",
    "#     total_loss.append(epoch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epo = range(80)\n",
    "# plt.plot(epo, total_loss)\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_word(context_words):\n",
    "#     context_ids = torch.tensor([word_to_idx[w] for w in context_words])\n",
    "#     with torch.no_grad():\n",
    "#         preds = model(context_ids)\n",
    "#         _, predicted_idx = torch.max(preds, 1)\n",
    "#         predicted_word = idx_to_word[predicted_idx.item()]\n",
    "#     return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# context = ['से', 'घृणा', 'होती', 'है।']\n",
    "# predicted = predict_word(context)\n",
    "# print(f\"Context: {context}\")\n",
    "# print(f\"Predicted word: {predicted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skip grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "skips = []\n",
    "for i in range(1, len(words)-1):\n",
    "    context = [words[i-1], words[i+1]]\n",
    "    target = words[i]\n",
    "    for w in context:\n",
    "        skips.append((target, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('से', 'घृणा'), ('से', 'घृणा')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skips[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'से'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context, target = skips[0]\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the continous BOW\n",
    "class skipgram(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(skipgram, self).__init__()\n",
    "\n",
    "        # 1 x embed_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.linear1 = nn.Linear(embed_dim, 128)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # 1 x vocab size\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = sum(self.embeddings(inputs)).view(1, -1)\n",
    "        out = self.linear1(embeds)\n",
    "        out = self.activation(out)\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = skipgram(vocab_size=vocab_size, embed_dim=embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 4.63024547215431\n",
      "Epoch: 50 | Loss: 1.682304440006133\n",
      "Epoch: 100 | Loss: 1.4884054127239412\n",
      "Epoch: 150 | Loss: 1.3989338730612109\n",
      "Epoch: 200 | Loss: 1.3481784066365612\n",
      "Epoch: 250 | Loss: 1.3151459206015832\n",
      "Epoch: 300 | Loss: 1.2910158444316155\n",
      "Epoch: 350 | Loss: 1.2729832224788205\n",
      "Epoch: 400 | Loss: 1.2585539351547919\n",
      "Epoch: 450 | Loss: 1.246944296023538\n",
      "Epoch: 500 | Loss: 1.2367167268549242\n",
      "Epoch: 550 | Loss: 1.2281555761733363\n",
      "Epoch: 600 | Loss: 1.2206412532156514\n",
      "Epoch: 650 | Loss: 1.2141713040970987\n",
      "Epoch: 700 | Loss: 1.2079993073017365\n",
      "Epoch: 750 | Loss: 1.20286241870734\n",
      "Epoch: 800 | Loss: 1.1981705857380744\n",
      "Epoch: 850 | Loss: 1.1936729675339115\n",
      "Epoch: 900 | Loss: 1.1897742356504164\n",
      "Epoch: 950 | Loss: 1.1864567872497342\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "total_loss = []\n",
    "\n",
    "for epoch in range(1000):\n",
    "    epoch_loss = 0\n",
    "    for target, context in skips:\n",
    "        # Convert words to indices\n",
    "        target_id = torch.tensor([word_to_idx[target]])\n",
    "        context_id = torch.tensor([word_to_idx[context]])\n",
    "        \n",
    "        # Forward pass\n",
    "        preds = model(target_id)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(preds, context_id)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch} | Loss: {epoch_loss/len(skips)}')\n",
    "\n",
    "    total_loss.append(epoch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_context(word, num_words=5):\n",
    "    if word not in word_to_idx:\n",
    "        return []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        word_idx = torch.tensor([word_to_idx[word]])\n",
    "        output = model(word_idx)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        top_indices = torch.topk(probabilities[0], num_words).indices\n",
    "        \n",
    "    return [idx_to_word[idx.item()] for idx in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(seed_word, length=6):\n",
    "    if seed_word not in word_to_idx:\n",
    "        return \"Seed word not in vocabulary\"\n",
    "    \n",
    "    sentence = [seed_word]\n",
    "    current_word = seed_word\n",
    "    \n",
    "    for _ in range(length - 1):\n",
    "        # Get context predictions for current word\n",
    "        context_words = predict_context(current_word)\n",
    "        \n",
    "        # Filter out words already in sentence to avoid repetition\n",
    "        new_words = [w for w in context_words if w not in sentence]\n",
    "        if not new_words:\n",
    "            break\n",
    "            \n",
    "        next_word = new_words[0]  # Taking the most probable word\n",
    "        sentence.append(next_word)\n",
    "        current_word = next_word\n",
    "    \n",
    "    return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentence: ज्ञान भी बड़े भाई को दे\n"
     ]
    }
   ],
   "source": [
    "word = \"ज्ञान\"\n",
    "sentence = generate_sentence(word, length=6)\n",
    "print(f\"Generated sentence: {sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
